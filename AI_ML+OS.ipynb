{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBFdetS6aft6fGJ51NgFEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshupriyank04/AI-ML-OS/blob/main/AI_ML%2BOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTJhYp5FH4tV"
      },
      "outputs": [],
      "source": [
        "#basic import utilities\n",
        "import random  #for generating random process burst times and arrival times\n",
        "import numpy as np #for numerical operations in the data prep section\n",
        "import pandas as pd #for storing training data and process logs\n",
        "\n",
        "from copy import deepcopy #for deep copying process objects during simulations\n",
        "\n",
        "import math #for all math related operations\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor  #ML model to predict burst time\n",
        "from sklearn.model_selection import train_test_split #for data split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error #for evaluation\n",
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning, NotFittedError\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
        "\n",
        "import pickle #for saving and loading trained ML models\n",
        "\n",
        "import matplotlib.pyplot as plt #for plotting results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process class\n",
        "# This class represents a single process in the system.\n",
        "# It stores all the information regarding CPU + I/O simulation.\n",
        "\n",
        "class Process:\n",
        "    def __init__(self, pid, arrival_time, cpu_bursts, io_bursts, priority=1):\n",
        "        \"\"\"\n",
        "        Initialize a process object with necessary fields.\n",
        "        \"\"\"\n",
        "\n",
        "        self.pid = pid\n",
        "        self.arrival_time = arrival_time\n",
        "        self.cpu_bursts = cpu_bursts\n",
        "        self.io_bursts = io_bursts\n",
        "        self.priority = priority\n",
        "        # ML FLAGS (default values, will be set in generator)\n",
        "        self.process_type = None\n",
        "        self.is_cpu_bound = False\n",
        "        self.is_io_bound = False\n",
        "\n",
        "\n",
        "        # Index to track which CPU burst we are executing\n",
        "        self.current_burst_index = 0\n",
        "\n",
        "        # IMPORTANT: store the remaining burst time\n",
        "        self.remaining_burst_time = cpu_bursts[0]\n",
        "\n",
        "        # Process state\n",
        "        self.state = \"READY\"\n",
        "\n",
        "        # Bookkeeping values\n",
        "        self.start_time = None\n",
        "        self.completion_time = None\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "        self.response_time = None\n",
        "        self.executed_time = 0\n",
        "\n",
        "        # For ML feature logging\n",
        "        self.total_wait_time = 0\n",
        "        self.past_bursts = []\n",
        "\n",
        "    def is_completed(self):\n",
        "        \"\"\"\n",
        "        Return True if all CPU bursts have finished.\n",
        "        \"\"\"\n",
        "        return self.current_burst_index >= len(self.cpu_bursts)\n",
        "\n",
        "    def move_to_next_burst(self):\n",
        "        \"\"\"\n",
        "        Move to the next CPU burst after finishing the previous one.\n",
        "        Reset remaining time for that burst.\n",
        "        \"\"\"\n",
        "        self.current_burst_index += 1\n",
        "\n",
        "        if self.current_burst_index < len(self.cpu_bursts):\n",
        "            # Update the remaining burst time for the next burst\n",
        "            self.remaining_burst_time = self.cpu_bursts[self.current_burst_index]\n",
        "        else:\n",
        "            self.remaining_burst_time = 0  # No more bursts\n",
        "\n",
        "    def get_next_io_burst(self):\n",
        "        \"\"\"\n",
        "        Return the I/O burst corresponding to the current CPU burst index.\n",
        "        \"\"\"\n",
        "        if self.current_burst_index < len(self.io_bursts):\n",
        "            return self.io_bursts[self.current_burst_index]\n",
        "        return None\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        String representation for debug.\n",
        "        \"\"\"\n",
        "        return f\"Process(pid={self.pid}, arrival={self.arrival_time}, state={self.state})\"\n"
      ],
      "metadata": {
        "id": "srTmc8IyZKK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SECTION 3: WORKLOAD GENERATOR\n",
        "\n",
        "# This section generates synthetic processes with:\n",
        "#   - Random arrival times\n",
        "#   - Random CPU burst sequences\n",
        "#   - Random I/O burst sequences\n",
        "# Optionally tags processes as CPU-bound or IO-bound.\n",
        "\n",
        "\n",
        "def generate_random_cpu_bursts(num_bursts):\n",
        "    \"\"\"\n",
        "    Generate a list of random CPU burst lengths.\n",
        "    Each burst is between 1 and 20 time units.\n",
        "    \"\"\"\n",
        "    return [random.randint(1, 20) for _ in range(num_bursts)]\n",
        "\n",
        "\n",
        "def generate_random_io_bursts(num_bursts):\n",
        "    \"\"\"\n",
        "    Generate I/O bursts.\n",
        "    If there are N CPU bursts, then there are N-1 I/O bursts.\n",
        "    Each I/O burst is between 5 and 30 time units.\n",
        "    \"\"\"\n",
        "    if num_bursts <= 1:\n",
        "        return []\n",
        "    return [random.randint(5, 30) for _ in range(num_bursts - 1)]\n",
        "\n",
        "\n",
        "def generate_processes(num_processes, tag_process_type=True):\n",
        "    \"\"\"\n",
        "    Generate a list of Process objects with random attributes.\n",
        "\n",
        "    Parameters:\n",
        "    num_processes: number of processes to generate\n",
        "    tag_process_type: whether to label processes as CPU-bound or IO-bound\n",
        "\n",
        "    Returns:\n",
        "    A list of Process objects.\n",
        "    \"\"\"\n",
        "\n",
        "    process_list = []\n",
        "\n",
        "    for pid in range(1, num_processes + 1):\n",
        "\n",
        "        arrival_time = random.randint(0, 50)\n",
        "\n",
        "        num_bursts = random.randint(2, 5)\n",
        "\n",
        "        cpu_bursts = generate_random_cpu_bursts(num_bursts)\n",
        "        io_bursts = generate_random_io_bursts(num_bursts)\n",
        "\n",
        "        # Optional CPU/IO-bound tagging\n",
        "        if tag_process_type:\n",
        "            process_type = random.choice([\"CPU_BOUND\", \"IO_BOUND\"])\n",
        "\n",
        "            if process_type == \"CPU_BOUND\":\n",
        "                cpu_bursts = [random.randint(10, 20) for _ in range(num_bursts)]\n",
        "                io_bursts = [random.randint(5, 15) for _ in range(num_bursts - 1)]\n",
        "            else:\n",
        "                cpu_bursts = [random.randint(1, 8) for _ in range(num_bursts)]\n",
        "                io_bursts = [random.randint(15, 30) for _ in range(num_bursts - 1)]\n",
        "\n",
        "        # Create process\n",
        "        process = Process(\n",
        "            pid=pid,\n",
        "            arrival_time=arrival_time,\n",
        "            cpu_bursts=cpu_bursts,\n",
        "            io_bursts=io_bursts,\n",
        "            priority=random.randint(1, 5)\n",
        "        )\n",
        "\n",
        "        # Attach process type & ML flags\n",
        "        if tag_process_type:\n",
        "            process.process_type = process_type\n",
        "\n",
        "            # === REQUIRED FOR ML SCHEDULERS ===\n",
        "            if process_type == \"CPU_BOUND\":\n",
        "                process.is_cpu_bound = True\n",
        "                process.is_io_bound = False\n",
        "            else:\n",
        "                process.is_cpu_bound = False\n",
        "                process.is_io_bound = True\n",
        "\n",
        "        else:\n",
        "            process.process_type = \"UNSPECIFIED\"\n",
        "            process.is_cpu_bound = False\n",
        "            process.is_io_bound = False\n",
        "\n",
        "        process_list.append(process)\n",
        "\n",
        "    # Sort by arrival time\n",
        "    process_list.sort(key=lambda p: p.arrival_time)\n",
        "\n",
        "    return process_list\n",
        "\n",
        "\n",
        "def export_processes_to_csv(process_list, filename=\"process_workload.csv\"):\n",
        "    \"\"\"\n",
        "    Optional: Export the generated workload to a CSV for external analysis.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for p in process_list:\n",
        "        data.append({\n",
        "            \"PID\": p.pid,\n",
        "            \"Arrival_Time\": p.arrival_time,\n",
        "            \"CPU_Bursts\": p.cpu_bursts,\n",
        "            \"IO_Bursts\": p.io_bursts,\n",
        "            \"Priority\": p.priority,\n",
        "            \"Process_Type\": p.process_type\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "0Cnij5Yxb6U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processes = generate_processes(5)\n",
        "for p in processes:\n",
        "    print(p, p.cpu_bursts, p.io_bursts, p.process_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "037LQG8cx5Z3",
        "outputId": "01e96cd9-ef67-4ab6-f8f0-3a50963ff020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process(pid=1, arrival=9, state=READY) [13, 16, 12, 16, 14] [14, 6, 12, 13] CPU_BOUND\n",
            "Process(pid=3, arrival=17, state=READY) [17, 12, 15, 15] [7, 9, 12] CPU_BOUND\n",
            "Process(pid=4, arrival=20, state=READY) [7, 6] [19] IO_BOUND\n",
            "Process(pid=5, arrival=41, state=READY) [11, 15] [15] CPU_BOUND\n",
            "Process(pid=2, arrival=44, state=READY) [6, 1, 2, 1] [23, 27, 28] IO_BOUND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_process_ml_extended(ready_queue, model):\n",
        "    \"\"\"\n",
        "    Select the process with the lowest *predicted next CPU burst*.\n",
        "    \"\"\"\n",
        "\n",
        "    if not ready_queue:\n",
        "        return None\n",
        "\n",
        "    predictions = []\n",
        "    for p in ready_queue:\n",
        "        # Create feature vector (dummy previous burst = 0, safe defaults)\n",
        "        prev1 = p.past_bursts[-1] if p.past_bursts else 0\n",
        "        prev2 = p.past_bursts[-2] if len(p.past_bursts) >= 2 else 0\n",
        "\n",
        "        avg_past = np.mean(p.past_bursts) if p.past_bursts else 0\n",
        "        var_past = np.var(p.past_bursts) if len(p.past_bursts) > 1 else 0\n",
        "\n",
        "        remaining_bursts = len(p.cpu_bursts) - p.current_burst_index - 1\n",
        "        total_cpu_used = p.executed_time\n",
        "        total_waited = p.total_wait_time\n",
        "\n",
        "        total_io_so_far = sum(p.io_bursts[:p.current_burst_index]) if p.current_burst_index > 0 else 0\n",
        "        io_ratio = (total_io_so_far / total_cpu_used) if total_cpu_used > 0 else 0\n",
        "\n",
        "        is_cpu_bound = 1 if p.is_cpu_bound else 0\n",
        "        is_io_bound = 1 if p.is_io_bound else 0\n",
        "\n",
        "        features = np.array([\n",
        "            prev1, prev2, p.arrival_time, 1 if p.is_cpu_bound else 2, p.priority,\n",
        "            total_cpu_used, total_waited,\n",
        "            avg_past, var_past, remaining_bursts,\n",
        "            io_ratio, is_cpu_bound, is_io_bound\n",
        "        ]).reshape(1, -1)\n",
        "\n",
        "        pred = model.predict(features)[0]\n",
        "        pred = max(1, int(round(pred)))\n",
        "        predictions.append((p, pred))\n",
        "\n",
        "    # Choose process with minimum predicted burst time\n",
        "    selected = min(predictions, key=lambda x: x[1])[0]\n",
        "    return selected\n"
      ],
      "metadata": {
        "id": "QLcBYxCI2a5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def train_ml_models(df):\n",
        "    \"\"\"\n",
        "    Train both RF and XGBoost models.\n",
        "    \"\"\"\n",
        "\n",
        "    X = df.drop(columns=[\"next_burst\"]).values\n",
        "    y = df[\"next_burst\"].values\n",
        "\n",
        "    #  Random Forest (old)\n",
        "    rf = RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        random_state=42\n",
        "    )\n",
        "    rf.fit(X, y)\n",
        "\n",
        "    #  XGBoost (new)\n",
        "    xgb = XGBRegressor(\n",
        "        n_estimators=250,\n",
        "        learning_rate=0.08,\n",
        "        max_depth=6,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_alpha=1.5,\n",
        "        reg_lambda=1.0,\n",
        "        objective=\"reg:squarederror\"\n",
        "    )\n",
        "    xgb.fit(X, y)\n",
        "\n",
        "    print(\"Models trained: RF + XGB\")\n",
        "\n",
        "    return rf, xgb\n"
      ],
      "metadata": {
        "id": "lzhdHBAg2VEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SECTION 4: CPU SCHEDULING SIMULATOR (WITH ML LOGGING SUPPORT)\n",
        "\n",
        "# This section implements:\n",
        "#   - Ready queue\n",
        "#   - Waiting (I/O) queue\n",
        "#   - Global clock\n",
        "#   - Simulation loop\n",
        "#   - FCFS, SJF, SRTF scheduling policies\n",
        "#   - ML training data logging inside step 6.6\n",
        "\n",
        "\n",
        "\n",
        "def add_arriving_processes(clock, all_processes, ready_queue):\n",
        "    \"\"\"\n",
        "    Add all processes whose arrival_time == current clock tick to the ready queue.\n",
        "    \"\"\"\n",
        "    for process in all_processes:\n",
        "        if process.arrival_time == clock and process.state == \"READY\":\n",
        "            ready_queue.append(process)\n",
        "\n",
        "\n",
        "def update_waiting_queue(waiting_queue, ready_queue):\n",
        "    \"\"\"\n",
        "    Decrease I/O burst remaining times of processes in waiting_queue.\n",
        "    When an I/O burst finishes, move the process back to ready_queue.\n",
        "    \"\"\"\n",
        "    updated = []\n",
        "\n",
        "    for process, remaining_io in waiting_queue:\n",
        "        if remaining_io is None:\n",
        "            continue\n",
        "\n",
        "        remaining_io -= 1  # One tick of I/O completed\n",
        "\n",
        "        if remaining_io == 0:\n",
        "            process.state = \"READY\"\n",
        "            ready_queue.append(process)\n",
        "        else:\n",
        "            updated.append((process, remaining_io))\n",
        "\n",
        "    waiting_queue.clear()\n",
        "    waiting_queue.extend(updated)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# SCHEDULER SELECTION FUNCTIONS\n",
        "\n",
        "\n",
        "def select_process_fcfs(ready_queue):\n",
        "    \"\"\"First-Come First-Served.\"\"\"\n",
        "    if not ready_queue:\n",
        "        return None\n",
        "    return ready_queue[0]\n",
        "\n",
        "\n",
        "def select_process_sjf(ready_queue):\n",
        "    \"\"\"Shortest Job First (non-preemptive).\"\"\"\n",
        "    if not ready_queue:\n",
        "        return None\n",
        "    return min(ready_queue, key=lambda p: p.remaining_burst_time)\n",
        "\n",
        "\n",
        "def select_process_srtf(ready_queue):\n",
        "    \"\"\"Shortest Remaining Time First (preemptive).\"\"\"\n",
        "    if not ready_queue:\n",
        "        return None\n",
        "    return min(ready_queue, key=lambda p: p.remaining_burst_time)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# MAIN SIMULATION FUNCTION\n",
        "\n",
        "\n",
        "def run_scheduler(process_list, algorithm=\"fcfs\"):\n",
        "    \"\"\"\n",
        "    Run CPU scheduling simulation with FCFS, SJF, or SRTF.\n",
        "    Also logs ML samples whenever a CPU burst completes.\n",
        "    \"\"\"\n",
        "\n",
        "    processes = deepcopy(process_list)\n",
        "\n",
        "    ready_queue = []\n",
        "    waiting_queue = []\n",
        "    clock = 0\n",
        "\n",
        "    current_process = None\n",
        "    context_switches = 0\n",
        "\n",
        "    total_processes = len(processes)\n",
        "    terminated_count = 0\n",
        "\n",
        "    while terminated_count < total_processes:\n",
        "\n",
        "        # Step 6.1: Add newly arrived processes\n",
        "        add_arriving_processes(clock, processes, ready_queue)\n",
        "\n",
        "        # Step 6.2: Update waiting(I/O) queue\n",
        "        update_waiting_queue(waiting_queue, ready_queue)\n",
        "\n",
        "        # Step 6.3: If CPU idle, choose next process\n",
        "        if current_process is None:\n",
        "\n",
        "            if algorithm == \"fcfs\":\n",
        "                current_process = select_process_fcfs(ready_queue)\n",
        "            elif algorithm == \"sjf\":\n",
        "                current_process = select_process_sjf(ready_queue)\n",
        "            elif algorithm == \"srtf\":\n",
        "                current_process = select_process_srtf(ready_queue)\n",
        "            # elif algorithm == \"ml\":\n",
        "            #     current_process = select_process_ml(ready_queue, rf_model)\n",
        "            elif algorithm == \"ml-rf\":\n",
        "                current_process = select_process_ml_extended(ready_queue, rf_model)\n",
        "\n",
        "            elif algorithm == \"ml-xgb\":\n",
        "                current_process = select_process_ml_extended(ready_queue, xgb_model)\n",
        "\n",
        "                # If ML returns None (empty queue), skip safely\n",
        "                if current_process is not None:\n",
        "                  # Safety: ensure burst time positive\n",
        "                  if current_process.remaining_burst_time <= 0:\n",
        "                    current_process.remaining_burst_time = 1\n",
        "\n",
        "            if current_process is not None:\n",
        "                ready_queue.remove(current_process)\n",
        "                context_switches += 1\n",
        "\n",
        "                if current_process.start_time is None:\n",
        "                    current_process.start_time = clock\n",
        "\n",
        "                if current_process.response_time is None:\n",
        "                    current_process.response_time = clock - current_process.arrival_time\n",
        "\n",
        "                current_process.state = \"RUNNING\"\n",
        "\n",
        "        else:\n",
        "            # Preemption check (SRTF)\n",
        "            if algorithm == \"srtf\" and ready_queue:\n",
        "                shortest_ready = select_process_srtf(ready_queue)\n",
        "\n",
        "                if shortest_ready.remaining_burst_time < current_process.remaining_burst_time:\n",
        "                    current_process.state = \"READY\"\n",
        "                    ready_queue.append(current_process)\n",
        "\n",
        "                    current_process = shortest_ready\n",
        "                    ready_queue.remove(shortest_ready)\n",
        "                    context_switches += 1\n",
        "\n",
        "                    if current_process.start_time is None:\n",
        "                        current_process.start_time = clock\n",
        "\n",
        "                    if current_process.response_time is None:\n",
        "                        current_process.response_time = clock - current_process.arrival_time\n",
        "\n",
        "                    current_process.state = \"RUNNING\"\n",
        "\n",
        "        # Step 6.4: Run CPU for 1 time unit\n",
        "        if current_process is not None:\n",
        "            current_process.remaining_burst_time -= 1\n",
        "            current_process.executed_time += 1\n",
        "\n",
        "\n",
        "            # Step 6.6: Burst completion\n",
        "\n",
        "            if current_process.remaining_burst_time == 0:\n",
        "\n",
        "              # Determine index of burst that just finished\n",
        "              finished_index = current_process.current_burst_index\n",
        "\n",
        "              # Safely get that burst value\n",
        "              just_completed_burst = current_process.cpu_bursts[finished_index]\n",
        "\n",
        "              # Add to past burst history\n",
        "              current_process.past_bursts.append(just_completed_burst)\n",
        "\n",
        "              # Determine next burst (target for ML)\n",
        "              if finished_index + 1 < len(current_process.cpu_bursts):\n",
        "                next_burst_target = current_process.cpu_bursts[finished_index + 1]\n",
        "              else:\n",
        "                next_burst_target = None\n",
        "\n",
        "              # Log ML training sample\n",
        "              log_training_sample(current_process, next_burst_target)\n",
        "\n",
        "              # Move to next CPU burst (increments burst index)\n",
        "              current_process.move_to_next_burst()\n",
        "\n",
        "              # Now check if more bursts exist\n",
        "              if not current_process.is_completed():\n",
        "\n",
        "                next_io = current_process.get_next_io_burst()\n",
        "\n",
        "                if next_io is not None:\n",
        "                  current_process.state = \"WAITING\"\n",
        "                  waiting_queue.append((current_process, next_io))\n",
        "                else:\n",
        "                  current_process.state = \"TERMINATED\"\n",
        "                  current_process.completion_time = clock + 1\n",
        "                  terminated_count += 1\n",
        "\n",
        "              else:\n",
        "                current_process.state = \"TERMINATED\"\n",
        "                current_process.completion_time = clock + 1\n",
        "                terminated_count += 1\n",
        "\n",
        "              current_process = None  # CPU idle\n",
        "\n",
        "\n",
        "        # Step 6.7: Update waiting timers\n",
        "        for p in ready_queue:\n",
        "            p.waiting_time += 1\n",
        "            p.total_wait_time += 1\n",
        "\n",
        "        clock += 1\n",
        "\n",
        "\n",
        "    # Final metrics\n",
        "\n",
        "\n",
        "    total_wait = sum(p.waiting_time for p in processes)\n",
        "    total_turnaround = sum(p.completion_time - p.arrival_time for p in processes)\n",
        "    total_response = sum(p.response_time for p in processes)\n",
        "\n",
        "    metrics = {\n",
        "        \"avg_waiting_time\": total_wait / total_processes,\n",
        "        \"avg_turnaround_time\": total_turnaround / total_processes,\n",
        "        \"avg_response_time\": total_response / total_processes,\n",
        "        \"context_switches\": context_switches\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "TkgI2hEezA0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SECTION 5: LOGGING TRAINING DATA FOR ML\n",
        "\n",
        "# Logs training samples every time a CPU burst completes.\n",
        "# Now includes extended feature set.\n",
        "\n",
        "\n",
        "ml_training_data = []   # Global dataset storage\n",
        "\n",
        "\n",
        "def log_training_sample(process, next_burst):\n",
        "    \"\"\"\n",
        "    Log one ML training sample when a CPU burst finishes.\n",
        "\n",
        "    Parameters:\n",
        "        process     : Process object\n",
        "        next_burst  : Next CPU burst length (target label)\n",
        "    \"\"\"\n",
        "\n",
        "    prev_bursts = process.past_bursts\n",
        "\n",
        "    #  OLD FEATURES (kept exactly same order)\n",
        "    prev1 = prev_bursts[-1] if len(prev_bursts) >= 1 else 0\n",
        "    prev2 = prev_bursts[-2] if len(prev_bursts) >= 2 else 0\n",
        "\n",
        "    # Process type â†’ numeric encoding\n",
        "    if process.process_type == \"CPU_BOUND\":\n",
        "        proc_type = 1\n",
        "    elif process.process_type == \"IO_BOUND\":\n",
        "        proc_type = 2\n",
        "    else:\n",
        "        proc_type = 0\n",
        "\n",
        "    arrival = process.arrival_time\n",
        "    priority = process.priority\n",
        "    total_cpu_used = process.executed_time\n",
        "    total_waited = process.total_wait_time\n",
        "\n",
        "    # NEW EXTENDED FEATURES\n",
        "\n",
        "    # Avg & variance of past burst lengths\n",
        "    avg_past = np.mean(prev_bursts) if len(prev_bursts) > 0 else 0\n",
        "    var_past = np.var(prev_bursts) if len(prev_bursts) > 1 else 0\n",
        "\n",
        "    # Remaining number of CPU bursts\n",
        "    remaining_bursts = len(process.cpu_bursts) - process.current_burst_index - 1\n",
        "\n",
        "    # Compute I/O ratio so far\n",
        "    if process.current_burst_index > 0:\n",
        "        total_io_so_far = sum(process.io_bursts[:process.current_burst_index])\n",
        "    else:\n",
        "        total_io_so_far = 0\n",
        "\n",
        "    io_ratio = (total_io_so_far / total_cpu_used) if total_cpu_used > 0 else 0\n",
        "\n",
        "    # Boolean CPU/IO bound flags\n",
        "    is_cpu_bound = 1 if process.process_type == \"CPU_BOUND\" else 0\n",
        "    is_io_bound = 1 if process.process_type == \"IO_BOUND\" else 0\n",
        "\n",
        "    # BUILD SAMPLE ROW\n",
        "\n",
        "    sample = {\n",
        "        # OLD\n",
        "        \"prev1\": prev1,\n",
        "        \"prev2\": prev2,\n",
        "        \"arrival_time\": arrival,\n",
        "        \"process_type\": proc_type,\n",
        "        \"priority\": priority,\n",
        "        \"total_cpu_used\": total_cpu_used,\n",
        "        \"total_waited\": total_waited,\n",
        "\n",
        "        #  NEW\n",
        "        \"avg_past\": avg_past,\n",
        "        \"var_past\": var_past,\n",
        "        \"remaining_bursts\": remaining_bursts,\n",
        "        \"io_ratio\": io_ratio,\n",
        "        \"is_cpu_bound\": is_cpu_bound,\n",
        "        \"is_io_bound\": is_io_bound,\n",
        "\n",
        "        #  TARGET\n",
        "        \"next_burst\": next_burst if next_burst is not None else 0\n",
        "    }\n",
        "\n",
        "    # Add row to dataset\n",
        "    ml_training_data.append(sample)\n",
        "\n",
        "\n",
        "\n",
        "def save_ml_dataset(filename=\"ml_training_dataset.csv\"):\n",
        "    \"\"\"\n",
        "    Saves the collected ML samples to a CSV file.\n",
        "    Also returns the DataFrame for immediate training use.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(ml_training_data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "R6Qxgndc1dpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processes = generate_processes(5)\n",
        "\n",
        "print(\"FCFS:\", run_scheduler(processes, algorithm=\"fcfs\"))\n",
        "print(\"SJF :\", run_scheduler(processes, algorithm=\"sjf\"))\n",
        "print(\"SRTF:\", run_scheduler(processes, algorithm=\"srtf\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN6dhTcKzB-f",
        "outputId": "c89601ea-4984-44e0-ef51-9e04db7a67b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FCFS: {'avg_waiting_time': 70.8, 'avg_turnaround_time': 130.8, 'avg_response_time': 15.6, 'context_switches': 15}\n",
            "SJF : {'avg_waiting_time': 44.0, 'avg_turnaround_time': 104.0, 'avg_response_time': 26.2, 'context_switches': 15}\n",
            "SRTF: {'avg_waiting_time': 43.2, 'avg_turnaround_time': 103.2, 'avg_response_time': 18.4, 'context_switches': 17}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ml_training_data = []  # reset dataset\n",
        "\n",
        "processes = generate_processes(15)\n",
        "run_scheduler(processes, \"fcfs\")\n",
        "\n",
        "df = save_ml_dataset()\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cZJbv2Ep2FgH",
        "outputId": "a8b9c581-719d-4936-ba38-6e3251a29243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   prev1  prev2  arrival_time  process_type  priority  total_cpu_used  \\\n",
              "0     14      0             6             1         5              14   \n",
              "1     20      0            13             1         4              20   \n",
              "2      7      0            21             2         3               7   \n",
              "3      6      0            23             2         2               6   \n",
              "4      3      0            25             2         4               3   \n",
              "\n",
              "   total_waited  avg_past  var_past  remaining_bursts  io_ratio  is_cpu_bound  \\\n",
              "0             0      14.0       0.0                 3       0.0             1   \n",
              "1             7      20.0       0.0                 4       0.0             1   \n",
              "2            19       7.0       0.0                 1       0.0             0   \n",
              "3            24       6.0       0.0                 1       0.0             0   \n",
              "4            28       3.0       0.0                 4       0.0             0   \n",
              "\n",
              "   is_io_bound  next_burst  \n",
              "0            0          12  \n",
              "1            0          17  \n",
              "2            1           5  \n",
              "3            1           5  \n",
              "4            1           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86944ba3-cde9-4a76-95a7-59af1bcc88e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prev1</th>\n",
              "      <th>prev2</th>\n",
              "      <th>arrival_time</th>\n",
              "      <th>process_type</th>\n",
              "      <th>priority</th>\n",
              "      <th>total_cpu_used</th>\n",
              "      <th>total_waited</th>\n",
              "      <th>avg_past</th>\n",
              "      <th>var_past</th>\n",
              "      <th>remaining_bursts</th>\n",
              "      <th>io_ratio</th>\n",
              "      <th>is_cpu_bound</th>\n",
              "      <th>is_io_bound</th>\n",
              "      <th>next_burst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86944ba3-cde9-4a76-95a7-59af1bcc88e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86944ba3-cde9-4a76-95a7-59af1bcc88e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86944ba3-cde9-4a76-95a7-59af1bcc88e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b913297-77a0-4c5a-862a-e65bdb6413f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b913297-77a0-4c5a-862a-e65bdb6413f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b913297-77a0-4c5a-862a-e65bdb6413f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 34,\n  \"fields\": [\n    {\n      \"column\": \"prev1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          14,\n          20,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          5,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arrival_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 6,\n        \"max\": 47,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          44,\n          38,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"process_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"priority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cpu_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 1,\n        \"max\": 68,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          1,\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_waited\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74,\n        \"min\": 0,\n        \"max\": 246,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          229,\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_past\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.072540055144219,\n        \"min\": 1.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          13.0,\n          6.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"var_past\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.4449017747845305,\n        \"min\": 0.0,\n        \"max\": 17.555555555555557,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"remaining_bursts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"io_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3729680903289236,\n        \"min\": 0.0,\n        \"max\": 5.25,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0,\n          5.153846153846154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_cpu_bound\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_io_bound\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"next_burst\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          15,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SECTION 6: ML MODEL TRAINING\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Features and target\n",
        "X = df[[\"prev1\", \"prev2\", \"arrival_time\", \"process_type\", \"priority\",\n",
        "        \"total_cpu_used\", \"total_waited\"]]\n",
        "\n",
        "y = df[\"next_burst\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "sc7BI3_XFdGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ML model\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "s1VreoweFgL7",
        "outputId": "04be7c55-1f93-4e94-8656-ab36a0cad2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "preds = rf_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(\"MAE :\", mae)\n",
        "print(\"RMSE:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtZE-kFLFi4G",
        "outputId": "18d67c75-6b5d-4b5a-9959-0e601b8e0024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "MAE : 2.0642857142857145\n",
            "RMSE: 2.419321038166346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(rf_model, \"trained_scheduler_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyl0r2NcFlGJ",
        "outputId": "0fe977b0-2bb9-4fb1-b568-0cbdc4b88b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_scheduler_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(process):\n",
        "    \"\"\"\n",
        "    Extract extended ML input features for prediction.\n",
        "    Must match dataset used during training.\n",
        "    \"\"\"\n",
        "\n",
        "    # OLD FIELDS (must stay in same order)\n",
        "    prev_bursts = process.past_bursts\n",
        "    prev1 = prev_bursts[-1] if len(prev_bursts) >= 1 else 0\n",
        "    prev2 = prev_bursts[-2] if len(prev_bursts) >= 2 else 0\n",
        "\n",
        "    # Encode type using your scheme\n",
        "    if process.process_type == \"CPU_BOUND\":\n",
        "        proc_type = 1\n",
        "    elif process.process_type == \"IO_BOUND\":\n",
        "        proc_type = 2\n",
        "    else:\n",
        "        proc_type = 0\n",
        "\n",
        "    arrival = process.arrival_time\n",
        "    priority = process.priority\n",
        "    total_cpu_used = process.executed_time\n",
        "    total_waited = process.total_wait_time\n",
        "\n",
        "    # NEW EXTENDED FEATURES\n",
        "    avg_past = np.mean(prev_bursts) if len(prev_bursts) > 0 else 0\n",
        "    var_past = np.var(prev_bursts) if len(prev_bursts) > 1 else 0\n",
        "\n",
        "    remaining_bursts = len(process.cpu_bursts) - process.current_burst_index - 1\n",
        "\n",
        "    # IO ratio calculation\n",
        "    if process.current_burst_index > 0:\n",
        "        total_io_so_far = sum(process.io_bursts[:process.current_burst_index])\n",
        "    else:\n",
        "        total_io_so_far = 0\n",
        "\n",
        "    io_ratio = (total_io_so_far / total_cpu_used) if total_cpu_used > 0 else 0\n",
        "\n",
        "    # CPU/IO bound flags\n",
        "    is_cpu_bound = 1 if process.process_type == \"CPU_BOUND\" else 0\n",
        "    is_io_bound = 1 if process.process_type == \"IO_BOUND\" else 0\n",
        "\n",
        "    return [\n",
        "        prev1, prev2,\n",
        "        arrival,\n",
        "        proc_type,\n",
        "        priority,\n",
        "        total_cpu_used,\n",
        "        total_waited,\n",
        "\n",
        "        # extended\n",
        "        avg_past,\n",
        "        var_past,\n",
        "        remaining_bursts,\n",
        "        io_ratio,\n",
        "        is_cpu_bound,\n",
        "        is_io_bound\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "12kdVcFTFlH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SECTION 8: ML-BASED PROCESS SELECTOR\n",
        "\n",
        "\n",
        "def select_process_ml(ready_queue, model):\n",
        "    \"\"\"\n",
        "    ML-based selection: choose process with minimum predicted next CPU burst.\n",
        "    Prediction is clamped to minimum 1 to avoid scheduling lock-ups.\n",
        "    \"\"\"\n",
        "    if not ready_queue:\n",
        "        return None\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for process in ready_queue:\n",
        "        features = extract_features(process)\n",
        "\n",
        "        predicted_burst = model.predict([features])[0]\n",
        "\n",
        "        # Prevent zero or negative predictions\n",
        "        predicted_burst = max(1, int(predicted_burst))\n",
        "\n",
        "        predictions.append((predicted_burst, process))\n",
        "\n",
        "    predictions.sort(key=lambda x: x[0])\n",
        "    return predictions[0][1]\n",
        "\n"
      ],
      "metadata": {
        "id": "rZMNh3JlIlbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 17: Generate LARGE ML training dataset\n",
        "\n",
        "\n",
        "print(\"STEP 17 â†’ Generating large ML dataset...\")\n",
        "\n",
        "ml_training_data = []   # reset dataset\n",
        "\n",
        "NUM_BATCHES = 30            # number of independent simulations\n",
        "PROCESSES_PER_BATCH = 50     # number of processes per simulation\n",
        "\n",
        "for b in range(NUM_BATCHES):\n",
        "    processes = generate_processes(PROCESSES_PER_BATCH)\n",
        "\n",
        "    # Run scheduler in FCFS mode (good for learning burst behavior)\n",
        "    run_scheduler(processes, \"fcfs\")\n",
        "\n",
        "print(\"Large ML dataset created!\")\n",
        "print(\"Total samples collected:\", len(ml_training_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BNTeedyxjim",
        "outputId": "fcaebdd0-0d2e-4a22-d952-9a7a79a19445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 17 â†’ Generating large ML dataset...\n",
            "Large ML dataset created!\n",
            "Total samples collected: 3674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 18: Save dataset & Train the Random Forest\n",
        "\n",
        "\n",
        "print(\"\\nSTEP 18 â†’ Training Random Forest on large dataset...\")\n",
        "\n",
        "df = save_ml_dataset()   # convert logged samples to DataFrame\n",
        "\n",
        "X = df.drop(\"next_burst\", axis=1)\n",
        "y = df[\"next_burst\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=250,\n",
        "    max_depth=12,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d776sSV6xpzf",
        "outputId": "a405c286-4217-4067-e249-e2b5b3f5ee1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 18 â†’ Training Random Forest on large dataset...\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 19: Evaluate predictive accuracy\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "pred = rf_model.predict(X_test)\n",
        "\n",
        "print(\"\\nMODEL PERFORMANCE\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, pred))\n",
        "print(\"RÂ² :\", r2_score(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hri8pddFxtXP",
        "outputId": "25780137-d704-40cd-bda9-cd6ffc1c1d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL PERFORMANCE\n",
            "MAE: 2.4850318480067894\n",
            "RÂ² : 0.7630251743387675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # STEP 20: Benchmark ML vs FCFS, SJF, SRTF\n",
        "\n",
        "\n",
        "# print(\"\\nSTEP 20 â†’ Benchmarking ML vs classic schedulers\")\n",
        "\n",
        "# # Generate a brand new workload for fair comparison\n",
        "# test_processes = generate_processes(25)\n",
        "\n",
        "# # Run all schedulers on IDENTICAL deep copies\n",
        "# import copy\n",
        "# fcfs_result = run_scheduler(copy.deepcopy(test_processes), \"fcfs\")\n",
        "# sjf_result  = run_scheduler(copy.deepcopy(test_processes), \"sjf\")\n",
        "# srtf_result = run_scheduler(copy.deepcopy(test_processes), \"srtf\")\n",
        "# ml_result   = run_scheduler(copy.deepcopy(test_processes), \"ml\")\n",
        "\n",
        "# print(\"\\n=== FINAL COMPARISON ===\")\n",
        "# print(\"FCFS :\", fcfs_result)\n",
        "# print(\"SJF  :\", sjf_result)\n",
        "# print(\"SRTF :\", srtf_result)\n",
        "# print(\"ML   :\", ml_result)\n"
      ],
      "metadata": {
        "id": "jOut30ygxzC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FULL PIPELINE: DATA GENERATION â†’ MODEL TRAINING â†’ BENCHMARKING\n",
        "\n",
        "\n",
        "print(\"STEP 1: Reset ML dataset \")\n",
        "ml_training_data = []\n",
        "\n",
        "\n",
        "\n",
        "# STEP 2: Generate large ML dataset by running schedulers\n",
        "\n",
        "print(\"STEP 2: Generating ML training dataset\")\n",
        "\n",
        "NUM_WORKLOADS = 50      # You can increase to 100 or 200 if needed\n",
        "PROCS_PER_WORKLOAD = 25\n",
        "\n",
        "for w in range(NUM_WORKLOADS):\n",
        "    procs = generate_processes(PROCS_PER_WORKLOAD)\n",
        "\n",
        "    # Run classic schedulers (these log ML samples)\n",
        "    run_scheduler(procs, \"fcfs\")\n",
        "    run_scheduler(procs, \"sjf\")\n",
        "    run_scheduler(procs, \"srtf\")\n",
        "\n",
        "    if w % 10 == 0:\n",
        "        print(f\"  â†’ Processed workload {w}/{NUM_WORKLOADS}\")\n",
        "\n",
        "print(\"Dataset collection complete.\")\n",
        "print(f\"Total ML samples: {len(ml_training_data)}\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# STEP 3: Save Dataset\n",
        "# -------------------------------------------------------------\n",
        "print(\"\\n STEP 3: Saving dataset to CSV\")\n",
        "df = save_ml_dataset(\"ml_training_dataset.csv\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# STEP 4: Train RF + XGB Models\n",
        "# -------------------------------------------------------------\n",
        "print(\"\\n STEP 4: Training ML models (RF & XGB)\")\n",
        "rf_model, xgb_model = train_ml_models(df)\n",
        "print(\"Models trained successfully.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B12FOn_L5gU1",
        "outputId": "320788f8-0cdc-4f55-f4ce-6b80148cc7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STEP 1: Reset ML dataset ===\n",
            "=== STEP 2: Generating ML training dataset... ===\n",
            "  â†’ Processed workload 0/50\n",
            "  â†’ Processed workload 10/50\n",
            "  â†’ Processed workload 20/50\n",
            "  â†’ Processed workload 30/50\n",
            "  â†’ Processed workload 40/50\n",
            "Dataset collection complete.\n",
            "Total ML samples: 9228\n",
            "\n",
            "=== STEP 3: Saving dataset to CSV ===\n",
            "   prev1  prev2  arrival_time  process_type  priority  total_cpu_used  \\\n",
            "0      5      0             0             2         4               5   \n",
            "1      3      0             4             2         1               3   \n",
            "2     20      0             6             1         2              20   \n",
            "3     16      0            12             1         5              16   \n",
            "4      3      0            15             2         1               3   \n",
            "\n",
            "   total_waited  avg_past  var_past  remaining_bursts  io_ratio  is_cpu_bound  \\\n",
            "0             0       5.0       0.0                 4       0.0             0   \n",
            "1             1       3.0       0.0                 3       0.0             0   \n",
            "2             2      20.0       0.0                 3       0.0             1   \n",
            "3            16      16.0       0.0                 1       0.0             1   \n",
            "4            29       3.0       0.0                 2       0.0             0   \n",
            "\n",
            "   is_io_bound  next_burst  \n",
            "0            1           4  \n",
            "1            1           2  \n",
            "2            0          12  \n",
            "3            0          12  \n",
            "4            1           1  \n",
            "\n",
            "=== STEP 4: Training ML models (RF & XGB)... ===\n",
            "Models trained: RF + XGB\n",
            "Models trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 5: Benchmark All Schedulers\n",
        "\n",
        "print(\"\\n STEP 5: Benchmarking all schedulers \")\n",
        "\n",
        "TEST_PROCESSES = 20\n",
        "test_procs = generate_processes(TEST_PROCESSES)\n",
        "\n",
        "results = {\n",
        "    \"FCFS\": run_scheduler(deepcopy(test_procs), \"fcfs\"),\n",
        "    \"SJF\": run_scheduler(deepcopy(test_procs), \"sjf\"),\n",
        "    \"SRTF\": run_scheduler(deepcopy(test_procs), \"srtf\"),\n",
        "    \"ML-RF\": run_scheduler(deepcopy(test_procs), \"ml-rf\"),\n",
        "    \"ML-XGB\": run_scheduler(deepcopy(test_procs), \"ml-xgb\"),\n",
        "}\n",
        "\n",
        "# Pretty-print results\n",
        "print(\"\\n FINAL COMPARISON \")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name:6} : {metrics}\")\n",
        "\n",
        "print(\"\\nDONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spZgH2RE8LhW",
        "outputId": "c802e30b-a237-42d1-cf63-02f101aa37f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== STEP 5: Benchmarking all schedulers ===\n",
            "\n",
            "=== FINAL COMPARISON ===\n",
            "FCFS   : {'avg_waiting_time': 242.0, 'avg_turnaround_time': 288.5, 'avg_response_time': 75.75, 'context_switches': 52}\n",
            "SJF    : {'avg_waiting_time': 132.25, 'avg_turnaround_time': 178.75, 'avg_response_time': 95.05, 'context_switches': 52}\n",
            "SRTF   : {'avg_waiting_time': 131.95, 'avg_turnaround_time': 178.45, 'avg_response_time': 93.75, 'context_switches': 64}\n",
            "ML-RF  : {'avg_waiting_time': 159.25, 'avg_turnaround_time': 205.75, 'avg_response_time': 69.4, 'context_switches': 52}\n",
            "ML-XGB : {'avg_waiting_time': 172.25, 'avg_turnaround_time': 218.75, 'avg_response_time': 66.75, 'context_switches': 52}\n",
            "\n",
            "=== DONE ===\n"
          ]
        }
      ]
    }
  ]
}